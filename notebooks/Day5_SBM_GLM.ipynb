{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 5. Surface-Based Morphometry on MRiShare dataset\n",
    "============================================\n",
    "\n",
    "This example uses Surface-Based Morphometry (VBM) to study the relationship\n",
    "between aging, sex and cortical thickness and/or surface area.\n",
    "\n",
    "The data come from the MRiShare database, which have been processed with \n",
    "Freesurfer v6.0 pipeline inside ABACI to create VBM maps.\n",
    "\n",
    "\n",
    "SBM analysis of aging\n",
    "---------------------\n",
    "\n",
    "We run a standard GLM analysis to study the association between age\n",
    "and surface-based metrics for each vertices from the Freesurfer data.\n",
    "\n",
    "We will use the same sample_mrishare_subinfo.csv to construct design matrices\n",
    "and run GLM analysis using mri_glm from Freesurfer. After preparing necessary input files, \n",
    "you can use this tool either directly in terminal or in this notebook, or using nipype\n",
    "interface.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors:  Ami Tsuchida <atsuch@gmail.com>, July, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input design files\n",
    "------------------\n",
    "\n",
    "The principle of design matrix is exactly the same for running SBM analysis using Freesurfer. \n",
    "However, Freesurfer program will take either one of the following format, so here you will practice\n",
    "creating both types.\n",
    "\n",
    "1. FSGD file \n",
    "\n",
    "2. Design mat file\n",
    "\n",
    "The first type is actually just a text file with information about any categorical variables in your design, and\n",
    "the rest of the continuous variable. From this file, it **automatically creates your design matrix file used for the actualy GLM analysis**. \n",
    "\n",
    "Here you can look at the description of this type of input here (https://surfer.nmr.mgh.harvard.edu/fswiki/FsgdFormat). You can also follow the example link to see the examples of these files for different types of design.\n",
    "\n",
    "The key thing to know about FSGD input option is that when you have any categorical variable of interest (e.g. Sex, healthy vs patients etc), it automatically creates a design that test for **different slopes and offset (DODS)**. You can read this (https://surfer.nmr.mgh.harvard.edu/fswiki/DodsDoss) for understanding what it means, but basically you will be testing interactions between your categorical variable and **every other continuous variables in your design**. This is fine as long as this is what you want to test, but if you have reasons to test for a simpler model, you will have to manually construct design mat file (second option).\n",
    "\n",
    "I suspect that most published studies using Freesurfer GLM use the first type of input, and never bother to create a simpler model with design mat, but it's good to know it can be done, and that sometimes it's probably more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the variables from sample subinfo.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dir= '../data/'\n",
    "sub_info = pd.read_csv(op.join(dat_dir, 'sample_mrishare_subinfo.csv'))\n",
    "sub_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjects = len(sub_info)\n",
    "n_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create FSGD input file and associated contrast files.\n",
    "\n",
    "This can be done with any text editor, but here we will do it with python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working dir for Freesurfer SBM and store the fsgd file there.\n",
    "\n",
    "fs_wd = '/home/padawan/fs_sbm'\n",
    "design1_wd = op.join(fs_wd, 'MyDesign1')\n",
    "design2_wd = op.join(fs_wd, 'MyDesign2')\n",
    "os.makedirs(design1_wd, exist_ok=True)\n",
    "os.makedirs(design2_wd, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to look at a meaningful intercept (i.e. mean CT/CSA across groups at mean age/score), let's create demeaned versions of the continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_info['Age_c'] = sub_info.Age - sub_info.Age.mean()\n",
    "sub_info['Score_c'] = sub_info.Score - sub_info.Score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsgd_lines = ['GroupDescriptorFile 1', 'Title SBMtest', 'Class F', 'Class M']\n",
    "\n",
    "# another line should contain 'Variables', then name of your continuous variables\n",
    "group_var = ['Sex']\n",
    "cont_vars = ['Age_c', 'Score_c']\n",
    "\n",
    "another_line_list = ['Variables'] + cont_vars\n",
    "another_line = ' '.join(another_line_list)\n",
    "fsgd_lines.append(another_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we grab columns that contain id and all the variables from the subinfo DF.\n",
    "\n",
    "fsgd_df = sub_info[['mrishare_id'] + group_var + cont_vars]\n",
    "\n",
    "# We also need to have an extra column that simply says 'Input'\n",
    "fsgd_df['Input'] = 'Input'\n",
    "\n",
    "# Reorder the df\n",
    "fsgd_df = fsgd_df[['Input', 'mrishare_id'] + group_var + cont_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we cerate a text file and save these info\n",
    "\n",
    "fsgd_file = op.join(design1_wd, 'SBMtest.fsgd')\n",
    "with open(fsgd_file, 'w') as f:\n",
    "    for line in fsgd_lines: # First write the lines\n",
    "        f.write(line + '\\n')\n",
    "    fsgd_df.to_csv(f, header=False, index=False, sep=' ') # Then add the DF without header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open the file to make sure it looks good. Now, let's also create some contrats you may be interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = {\n",
    "             'group.intercept': [0.5, 0.5, 0, 0, 0, 0], # Does mean of group intercepts differ from 0?\n",
    "             'group.diff': [1, -1, 0, 0, 0, 0], # Is there a sex diff bet group intercept after correcting for age and cognitive score?\n",
    "             'group-x-age': [0, 0, 1, -1, 0, 0], # Is there a difference bet group in the effect of age?\n",
    "             'group-x-score': [0, 0, 0, 0, 1, -1], # Is there a difference bet group in the effect of cognitive score?\n",
    "             'FM-age': [0, 0, 0.5, 0.5, 0, 0], # Is there any average age effect across sex after correcting for cognitive score?\n",
    "             'FM-score': [0, 0, 0, 0, 0.5, 0.5], # Is there any average score effect across sex after correcting for age?\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each contrast as mtx txt file\n",
    "\n",
    "# also keep contrast file names for a later use\n",
    "cont_files = []\n",
    "\n",
    "for contrast_name, contrast_list in contrasts.items():\n",
    "    contrast_file = op.join(design1_wd, '{}.mtx'.format(contrast_name))\n",
    "    with open(contrast_file, 'w') as f:\n",
    "        lines = [' '.join(str(val) for val in contrast) for contrast in contrast_list]\n",
    "        f.write('\\n'.join(lines))\n",
    "        \n",
    "    cont_files.append(contrast_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Design mat input file\n",
    "\n",
    "But let's say you know from prior studies/analyses that there is no Age by Sex interaction onthe CT or CSA values. But you still want to test the interaction between Sex and cognitive score. Although you can look at 'group-x-score' contrast above (and I suspect most people simply do that), technically it's more appropreate to look at this effect in a model that does not include Age by Sex terms. \n",
    "\n",
    "To test such model, you have to create design matrix file manually and skip FSGD. But it's not very difficult to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First You need two columns of 1 and 0 that represent each sex\n",
    "\n",
    "sex_M = np.array(sub_info.Sex.values == 'M')\n",
    "sex_F = np.array(sub_info.Sex.values == 'F')\n",
    "\n",
    "# Then you need one column for Age\n",
    "age = sub_info.Age.values\n",
    "\n",
    "# The last two columns are cogniive scores, but one for male and another for female\n",
    "score_M = np.multiply(sub_info.Score, sex_M)\n",
    "score_F = np.multiply(sub_info.Score, sex_F)\n",
    "\n",
    "# then finally put them in one array\n",
    "design_arr = np.vstack((sex_M, sex_F, age, score_M, score_F)).T\n",
    "design_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be saved as txt, but Freesurfer official documentation specifies matlab mat file format, so save in this format using scipy io.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat = {'X': design_arr}\n",
    "design_file = op.join(design2_wd, 'SBM_test2.mat')\n",
    "sio.savemat(design_file, design_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you create contrasts that should be used with the design you just created above? \n",
    "You don't have to include aevery possible contrast that can be tested. Just make sure to include contrast testing for the presence of Sex and Score interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each contrast as mtx txt file and save these filenames\n",
    "cont_files2 = []\n",
    "\n",
    "for contrast_name, contrast_list in contrasts.items():\n",
    "    contrast_file = op.join(design2_wd, '{}.mtx'.format(contrast_name))\n",
    "    with open(contrast_file, 'w') as f:\n",
    "        lines = [' '.join(str(val) for val in contrast) for contrast in contrast_list]\n",
    "        f.write('\\n'.join(lines))\n",
    "        \n",
    "    cont_files2.append(contrast_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse data\n",
    "------------\n",
    "\n",
    "### 1. Prepare CT/CSA data\n",
    "\n",
    "To run GLM analysis with Freesurfer, you first have to assemble your CT/CSA data for each subject using mris_preproc.\n",
    "\n",
    "Here I will use nipype interface to demonstrate, but you can check the cmdline to see equivalent command you would use if running directly in terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.freesurfer.model import MRISPreproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For many Freesurfer commands, you need to specify $SUBJECTS_DIR where you do all your freesurfer analysis.\n",
    "# To use pre-computed FS data from example subjects, we provide the following path\n",
    "\n",
    "fs_subjects_dir = '/data/rw_eleves/Cajal-Morphometry2019/derived_mrishare/freesurfer/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhCTpreproc = MRISPreproc()\n",
    "lhCTpreproc.inputs.surf_measure = 'thickness'\n",
    "lhCTpreproc.inputs.subjects_dir = fs_subjects_dir\n",
    "lhCTpreproc.inputs.target = 'fsaevrage'\n",
    "lhCTpreproc.inputs.hemi = 'lh'\n",
    "lhCTpreproc.inputs.out_file = op.join(fs_wd, 'stacked.lh.thickness.00.mgh')\n",
    "lhCTpreproc.inputs.subjects = list(sub_info.mrishare_id.values)\n",
    "lhCTpreproc.cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhCTpreproc.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command resamples each subject's left hemisphere thickness data to fsaverage. The output is a stacked thickness data in fsaverage space for the specified subjects.\n",
    "\n",
    "Note that you can specify the subjects either by giving the list of subjects as above, or from fsgd file (fsgd_file input in nipype or --fsgd in cmdline), or from a file containing a list of subjects (subject_file input in nipype or --f in cmdline) \n",
    "\n",
    "Next, you need to smooth the data to improve the robustness of statistical behavior, using mri_surf2surf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.freesurfer.utils import SurfaceSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhCTsmooth = SurfaceSmooth()\n",
    "lhCTsmooth.inputs.in_file = op.join(fs_wd, 'stacked.lh.thickness.00.mgh')\n",
    "lhCTsmooth.inputs.subject_id = 'fsaverage'\n",
    "lhCTsmooth.inputs.hemi = 'lh'\n",
    "lhCTsmooth.inputs.subjects_dir = fs_subjects_dir\n",
    "lhCTsmooth.inputs.fwhm = 10.0\n",
    "lhCTsmooth.inputs.cortex = True\n",
    "lhCTsmooth.inputs.out_file = op.join(fs_wd, 'stacked.lh.thickness.10.mgh')\n",
    "lhCTsmooth.cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it\n",
    "lhCTsmooth.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This smooths each subject's resampled data by 10mm FWHM.\n",
    "\"--cortex\" means only smooth areas in cortex (exclude medial wall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit GLM \n",
    "\n",
    "Now you have the image data ready. So we will use mri_glmfit to fit the model, first using the FSGD file as input, then we will try with design input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.freesurfer.model import GLMFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSGD input example \n",
    "\n",
    "lhSBMglmfit1 = GLMFit()\n",
    "lhSBMglmfit1.inputs.subjects_dir = fs_subjects_dir\n",
    "lhSBMglmfit1.inputs.surf = True\n",
    "lhSBMglmfit1.inputs.subject_id = target_atlas\n",
    "lhSBMglmfit1.inputs.hemi = 'lh'\n",
    "lhSBMglmfit1.inputs.cortex = True\n",
    "lhSBMglmfit1.inputs.fsgd = (fsgd_file, 'dods')\n",
    "lhSBMglmfit1.inputs.contrast = cont_files\n",
    "lhSBMglmfit1.inputs.glmdir = op.join(design1_wd, 'glm')\n",
    "lhSBMglmfit1.cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it\n",
    "lhSBMglmfit1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desing mat input example\n",
    "\n",
    "lhSBMglmfit2 = GLMFit()\n",
    "lhSBMglmfit2.inputs.subjects_dir = fs_subjects_dir\n",
    "lhSBMglmfit2.inputs.surf = True\n",
    "lhSBMglmfit2.inputs.subject_id = target_atlas\n",
    "lhSBMglmfit2.inputs.hemi = 'lh'\n",
    "lhSBMglmfit2.inputs.cortex = True\n",
    "lhSBMglmfit2.inputs.design = design_file\n",
    "lhSBMglmfit2.inputs.contrast = cont_files\n",
    "lhSBMglmfit2.inputs.glmdir = op.join(design2_wd, 'glm')\n",
    "lhSBMglmfit2.cmdline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it\n",
    "lhSBMglmfit2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When they finish running, checkout the output directory to see files that were generated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try visualzing one of the result p-val map using nilearn plotting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sig_map = op.join(design1_wd, 'glm', 'FM-age', 'sig.mgh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the interactive surface plotting in nilearn does not seem to suppor mgh format yet, we will first read this file using nibabel, and will pass image data as an array directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel.freesurfer.mghformat as fsmgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sig_map_im = fsmgh.load(age_sig_map)\n",
    "age_sig_map_dat = age_sig_map_im.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sig_map_dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, when passing a numpy array, the plot_surf function of nilearn expects the surface map to have a shape similar to morphometry data (files that end with .thickness, .curv, .sulc in Freesurfer). To demonstrate what this means, here we will load lh.sulc of the fsaverage and look at the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsaverage_dir = op.join(fs_subjects_dir, 'fsaverage')\n",
    "fsaverage_lh_infl = op.join(fsaverage_dir, 'surf', 'lh.inflated')\n",
    "fsaverage_lh_sulc =  op.join(fsaverage_dir, 'surf', 'lh.sulc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel.freesurfer.io as fsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_sulc_dat = fsio.read_morph_data(fsaverage_lh_sulc)\n",
    "lh_sulc_dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that they both contain data for 163842 vertices, but the array shape is not the same in thesetwo forms of data. To use plot_surf function, we have to reshape the sig map data by stripping the extra dimensions like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sig_map_dat_rs = np.reshape(age_sig_map_dat, (age_sig_map_dat.shape[0],))\n",
    "age_sig_map_dat_rs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overlay this with nilearn plotting, we just need to provide background surface image (fsaverage inflated, pial surfaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_surf(fsaverage_lh_infl, age_sig_map_dat_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map is unthresholded log p map (i.e. p < 0.01 = log p > 2). Let's try thresholding at 2 so that we can look at the map at this threhold. When thresholding, it's better to provide a background map for shading on the inflated brain (usually sulc image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot \n",
    "plotting.view_surf(fsaverage_lh_infl, age_sig_map_dat_rs, threshold=2, \n",
    "                   bg_map=fsaverage_lh_sulc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using this of freeview to check your results for different contrasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Comparison correction\n",
    "\n",
    "To correct for multiple comparisons, we can use mri_fdr for FDR correction, and mri_glmfit-sim for permutation. Unfortunately, nipype has not wrapped either of these function. Although mri_glmfit you used earlier seems to have a functionality for simulation analysis, the latest recommendation is to use mri_glmfit-sim permutation testing (you can read more about this under resources/multiplecomparisons.pdf).\n",
    "\n",
    "For this practical, we will simply use the commandline directly, either from this notebook or directly in terminal. But it's not all that difficult to wrap a missing function in nipype if you want to use the function within the context of a pipeline. As an example, I created a custom interface for mri_fdr in ginnipi_tools/interfaces/custom.py, so oyu can take a look at it to see how it can be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mri_fdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, your main input is sig.mgh from your contrast of interest. It can accept more than one input file, typically because you might usually want to correct for the same analysis in both R and L hemispheres. For the practical, can you try to correct for one hemisphere you did above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it finishes running, check the output and try to visualize it using a viewer of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mri_glmfit-sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes glm dir of your mri_glmfir as the input to perform permutations for contrasts found in that directory. To use the recommended permutation method, you specify --perm and the number of permutation as in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design1_glm = op.join(design1_wd, 'glm')\n",
    "\n",
    "!mri_glmfit-sim \\\n",
    "  --glmdir {design1_glm} \\\n",
    "  --perm 1000 4.0 abs \\\n",
    "  --cwp  0.05\\\n",
    "  --2spaces \\\n",
    "  --bg 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agein, once it finishes running, check the output using a viewer of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
